---
layout: splash
header:
  overlay_image: /assets/images/header.png  # Replace with the actual path to your image
  overlay_color: "#333"  # Optional: A hex color for the overlay (if not using an image)
  overlay_filter: 0.5  # Optional: A number between 0 and 1 to specify the opacity of the overlay
title: "Bridging Neurons and Symbols for Natural Language Processing and Knowledge Graphs Reasoning @ LREC-Coling 2024"  
# subtitle: "Neurons and symbols are Yin and Yang to solve NLP problems. Their interaction will unleash greater power than alone."
---

<div class="page__content">
    <section id="Workshop Scope">
        <h2>Overview</h2>
        <!---<p>Endowing machines with knowledge has long been regarded as one of the important goals of AI. Traditionally, symbols and their relations represent knowledge for natural language processing. Large language
models (LLMs) follow the tradition of connectionism and neural networks employing distributional numerical vectors/matrices to represent knowledge. This way, almost all knowledge types can be represented
and embodied into a unified semantic space. A cutting-edge research direction of neural computing is to move from associative thinking (System I) to rational thinking (System II). This may demand traditional
deep learning to go beyond the statistical learning framework, and make qualitative extensions to represent and reason with explicit knowledge. A variety of new learning biases has been proposed to narrow the gap
between higher-level cognition and traditional deep-learning. It is an open question how neural networks can reach deterministic rational reasoning at the level of symbolic AI. To sum up: the state-of-the-art in
deep learning for NLP and beyond shows that there are many open research questions to be addressed at the interface of symbolic and neural approaches and that bridging neurons and symbols may break the
glass ceiling of deep learning for NLP.</p>-->
        <p>Recent exploration shows that LLMs, e.g., ChatGPT, may pass the Turing test in human-like chatting
        but have limited capability even for simple reasoning tasks <a href="https://www.nature.com/articles/d41586-023-02361-7">(Biever, 2023)</a>. It remains unclear whether
        LLMs reason or not <a href="https://www.science.org/doi/10.1126/science.adj5957"> (Melanie, 2023)</a>. The mind of reasoning demonstrates dual-process phenomenon
        <a href="https://www.cambridge.org/core/books/abs/cambridge-handbook-of-computational-cognitive-sciences/cambridge-handbook-of-computational-cognitive-sciences/E5DBABB50DB8BB4A8FFD9B961D49DA99"> (Sun, 2023)</a> or ways of fast and slow thinking <a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow">(Kahneman, 2011)</a>. This follows two directions to exploring
        neural reasoning: starting from existing neural networks to enhance the reasoning performance with
        the target of symbolic-level reasoning, and starting from symbolic reasoning to explore its novel neural
        implementation. The two directions of exploration may meet somewhere in the middle on a <b>bridge</b>, a
        separate spatial representation supporting novel neural computing that differs from traditional neural networks
        and symbolic structures but inherits good features from both of them. So comes the name of our workshop,
        with a focus on Natural Language Processing and Knowledge Graph reasoning. A variety of cutting-edge
        research follows the first direction. This workshop promotes research in both directions, particularly
        seeking novel proposals from the second direction.</p>
    </section>

    <section id="Invited Speakers">
        <h2>Invited Speakers</h2>
        <ul>
            <li>Pascal Fung - The Hong Kong University of Science and Technology</li>
            <li>Alessandro Lenci - Università di Pisa</li>
             <li>Volker Tresp - Ludwig Maximilian University of Munich</li>
            <li>Juanzi Li - Tsinghua University</li>
        </ul>
    </section>

    <section id="Organizers">
        <h2>Organizers</h2>
        <div class="organizers">
          <!-- Row 1 -->
          <div class="organizer">
            <img src="/assets/images/tdong.jpg" alt="Tiansi Dong">
            <p><a href="https://tiansidr.github.io/">Tiansi Dong</a></p>
            <p>Fraunhofer IAIS</p>
          </div>
          <div class="organizer">
            <img src="/assets/images/EHinrichs.jpg" alt="Erhard Hinrichs">
            <p><a href="https://www.sfs.uni-tuebingen.de/~eh/">Erhard Hinrichs</a></p>
            <p>University of Tübingen</p>
          </div>
          <div class="organizer">
            <img src="/assets/images/zhenhan.jpg" alt="Zhen Han">
            <p><a href="https://www.linkedin.com/in/zhen-han-08a769128/?originalSubdomain=uk">Zhen Han</a></p>
            <p>Amazon Inc.</p>
          </div>
        </div>
        <div class="organizers">
          <!-- Row 2 -->
          <div class="organizer">
            <img src="/assets/images/liukang.jpg" alt="Kang Liu">
            <p><a href="http://www.nlpr.ia.ac.cn/cip/~liukang/">Kang Liu</a></p>
            <p>Chinese Academy of Sciences</p>
          </div>
          <div class="organizer">
            <img src="/assets/images/YangqiuSong.jpg" alt="Yangqiu Song" class="custom-position">
            <p><a href="https://www.cse.ust.hk/~yqsong/">Yangqiu Song</a></p>
            <p>The Hong Kong University of Science and Technology</p>
          </div>
          <div class="organizer">
            <img src="/assets/images/yixin.png" alt="Yixin Cao">
            <p><a href="https://computing.smu.edu.sg/faculty/profile/6241/yixin-cao">Yixin Cao</a></p>
            <p>Singapore Management University</p>
          </div>
        </div>
        <div class="organizers">
          <!-- Row 3 -->
          <div class="organizer">
            <img src="/assets/images/Hempelmann2018.jpg" alt="Christian F. Hempelmann">
            <p><a href="https://www.tamuc.edu/people/christian-f-hempelmann/">Christian F. Hempelmann</a></p>
            <p>Texas A&M-Commerce</p>
          </div>
        </div>
    </section>
</div>
